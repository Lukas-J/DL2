{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import librosa\n",
    "from utils import (\n",
    "    get_datasets,\n",
    "    waveform_to_spectrograms,\n",
    "    waveform_to_log_mel_spectrogram,\n",
    "    eval_and_save,\n",
    "    get_callbacks,\n",
    "    get_background_noise,\n",
    "    augment_fn,\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_raw, ds_val_raw, ds_test_raw = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, encoder):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.d1 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
    "        self.d2 = tf.keras.layers.Dense(30)\n",
    "\n",
    "    def call(self, x):\n",
    "        input_features, decoder_input_ids = x\n",
    "        x = self.encoder(input_features, decoder_input_ids=decoder_input_ids).last_hidden_state\n",
    "        x = x[:, -1, :]\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, TFWhisperModel\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = MyModel(TFWhisperModel.from_pretrained(\"openai/whisper-tiny\"))\n",
    "model.encoder.trainable = False\n",
    "\n",
    "batch_size = 2\n",
    "ds_train = ds_train_raw.batch(batch_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Lion(learning_rate=1e-5)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.load_weights(\"../epoch_0.weights.h5\")\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(1, epochs):\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for x_batch, y_batch in ds_train:\n",
    "        step += 1\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            inputs = [feature_extractor(tf.squeeze(x_batch)[i], return_tensors=\"tf\", sampling_rate=16000).input_features for i in range(x_batch.shape[0])]\n",
    "            inputs = tf.concat(inputs, axis=0)\n",
    "\n",
    "            tmp = [50258] * x_batch.shape[0] * 2\n",
    "            decoder_input_ids = tf.convert_to_tensor(tmp)\n",
    "            decoder_input_ids = tf.reshape(decoder_input_ids, (x_batch.shape[0], 2))\n",
    "\n",
    "            outputs = model((inputs, decoder_input_ids))\n",
    "\n",
    "            loss = loss_fn(y_batch, outputs)\n",
    "            print(loss)\n",
    "        # Backward pass\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        epoch_loss += loss.numpy() * batch_size\n",
    "        if step % 1000 == 0:\n",
    "            model.save_weights(f\"epoch_{epoch}_step_{step}.weights.h5\")\n",
    "\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(ds_train_raw)}\")\n",
    "    model.save_weights(f\"epoch_{epoch}.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test_raw.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for x_batch, y_batch in ds_test:\n",
    "    inputs = [feature_extractor(tf.squeeze(x_batch)[i], return_tensors=\"tf\", sampling_rate=16000).input_features for i in range(x_batch.shape[0])]\n",
    "    inputs = tf.concat(inputs, axis=0)\n",
    "\n",
    "    tmp = [50258] * x_batch.shape[0] * 2\n",
    "    decoder_input_ids = tf.convert_to_tensor(tmp)\n",
    "    decoder_input_ids = tf.reshape(decoder_input_ids, (x_batch.shape[0], 2))\n",
    "\n",
    "    outputs = model((inputs, decoder_input_ids))\n",
    "    preds.extend(tf.argmax(outputs, axis=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
