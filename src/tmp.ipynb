{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 17:03:54.386487: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 17:03:56.844752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from utils import (\n",
    "    get_datasets,\n",
    "    waveform_to_spectrograms,\n",
    "    waveform_to_log_mel_spectrogram,\n",
    "    eval_and_save,\n",
    "    get_callbacks,\n",
    "    CustomSchedule,\n",
    ")\n",
    "from Transformer import Transformer\n",
    "SEED = 1337\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51088 files belonging to 30 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 17:04:10.619188: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 17:04:11.061373: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 17:04:11.061455: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 17:04:11.072280: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 17:04:11.072388: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 17:04:11.072434: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 17:04:14.637330: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 17:04:14.637471: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 17:04:14.637489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-29 17:04:14.637570: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-29 17:04:14.638320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3840 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6798 files belonging to 30 classes.\n",
      "Found 6835 files belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "sample_rate = 16000\n",
    "frame_length = 255\n",
    "frame_step = 128\n",
    "num_mel_bins = 129\n",
    "ds_train_raw, ds_val_raw, ds_test_raw = get_datasets()\n",
    "model_type = \"Transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Transformer6.weights.h5\"\n",
    "config = {\n",
    "    \"Spectrogram\": \"Log-Mel\",\n",
    "    \"Regularization\": \"Dropout\",\n",
    "    \"Optimizer\": \"Adam\",\n",
    "    \"Learning Rate\": 0.001,\n",
    "    \"Batch Size\": 256,\n",
    "    \"d_model\": 256,\n",
    "    \"num_layers\": 4,\n",
    "    \"num_heads\": 2,\n",
    "    \"dropout_rate\": 0.2,\n",
    "}\n",
    "\n",
    "ds_train = (\n",
    "    ds_train_raw.batch(config[\"Batch Size\"])\n",
    "    .map(\n",
    "        lambda x, y: (\n",
    "            waveform_to_log_mel_spectrogram(\n",
    "                x,\n",
    "                sample_rate=sample_rate,\n",
    "                frame_length=frame_length,\n",
    "                frame_step=frame_step,\n",
    "                num_mel_bins=num_mel_bins,\n",
    "            ),\n",
    "            y,\n",
    "        )\n",
    "    )\n",
    "    .cache()\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "ds_val = (\n",
    "    ds_val_raw.batch(config[\"Batch Size\"])\n",
    "    .map(\n",
    "        lambda x, y: (\n",
    "            waveform_to_log_mel_spectrogram(\n",
    "                x,\n",
    "                sample_rate=sample_rate,\n",
    "                frame_length=frame_length,\n",
    "                frame_step=frame_step,\n",
    "                num_mel_bins=num_mel_bins,\n",
    "            ),\n",
    "            y,\n",
    "        )\n",
    "    )\n",
    "    .cache()\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "ds_test = (\n",
    "    ds_test_raw.batch(config[\"Batch Size\"])\n",
    "    .map(\n",
    "        lambda x, y: (\n",
    "            waveform_to_log_mel_spectrogram(\n",
    "                x,\n",
    "                sample_rate=sample_rate,\n",
    "                frame_length=frame_length,\n",
    "                frame_step=frame_step,\n",
    "                num_mel_bins=num_mel_bins,\n",
    "            ),\n",
    "            y,\n",
    "        )\n",
    "    )\n",
    "    .cache()\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714403084.726330    3929 service.cc:145] XLA service 0x7f9e6c014f90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714403084.728372    3929 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2060 with Max-Q Design, Compute Capability 7.5\n",
      "2024-04-29 17:04:46.440912: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-29 17:04:55.153550: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714403122.985898    4334 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_43', 1724 bytes spill stores, 1724 bytes spill loads\n",
      "\n",
      "I0000 00:00:1714403127.365262    4325 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 932 bytes spill stores, 932 bytes spill loads\n",
      "\n",
      "I0000 00:00:1714403127.943178    4328 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_32', 932 bytes spill stores, 932 bytes spill loads\n",
      "\n",
      "2024-04-29 17:05:45.392592: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng30{k2=1,k4=2,k5=1,k6=0,k7=0} for conv (f32[256,256,1,124]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,256,1,126]{3,2,1,0}, f32[256,256,1,3]{3,2,1,0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-04-29 17:05:45.418836: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.026267053s\n",
      "Trying algorithm eng30{k2=1,k4=2,k5=1,k6=0,k7=0} for conv (f32[256,256,1,124]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,256,1,126]{3,2,1,0}, f32[256,256,1,3]{3,2,1,0}), window={size=1x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-04-29 17:05:50.454340: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1714403182.144795    3929 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - accuracy: 0.0504 - loss: 3.7069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1714403559.747993    6494 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_43', 1724 bytes spill stores, 1724 bytes spill loads\n",
      "\n",
      "I0000 00:00:1714403561.925365    6488 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_32', 932 bytes spill stores, 932 bytes spill loads\n",
      "\n",
      "I0000 00:00:1714403563.993634    6482 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 932 bytes spill stores, 932 bytes spill loads\n",
      "\n",
      "2024-04-29 17:12:45.591134: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 12.71GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-29 17:12:45.662857: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.91GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 2s/step - accuracy: 0.0509 - loss: 3.7025 - val_accuracy: 0.3538 - val_loss: 2.1484\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 4s/step - accuracy: 0.5283 - loss: 1.5741 - val_accuracy: 0.8189 - val_loss: 0.6279\n",
      "Epoch 3/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 1s/step - accuracy: 0.8426 - loss: 0.5377 - val_accuracy: 0.8723 - val_loss: 0.4312\n",
      "Epoch 4/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 967ms/step - accuracy: 0.8951 - loss: 0.3622 - val_accuracy: 0.8926 - val_loss: 0.3719\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 877ms/step - accuracy: 0.9150 - loss: 0.2918 - val_accuracy: 0.8978 - val_loss: 0.3539\n",
      "Epoch 6/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 1s/step - accuracy: 0.9259 - loss: 0.2534 - val_accuracy: 0.9007 - val_loss: 0.3428\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 1s/step - accuracy: 0.9290 - loss: 0.2360 - val_accuracy: 0.8866 - val_loss: 0.3936\n",
      "Epoch 8/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 727ms/step - accuracy: 0.9321 - loss: 0.2199 - val_accuracy: 0.8779 - val_loss: 0.4297\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 1s/step - accuracy: 0.9355 - loss: 0.2099 - val_accuracy: 0.9123 - val_loss: 0.3192\n",
      "Epoch 10/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 1s/step - accuracy: 0.9386 - loss: 0.2008 - val_accuracy: 0.9154 - val_loss: 0.3062\n",
      "Epoch 11/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 1s/step - accuracy: 0.9366 - loss: 0.2013 - val_accuracy: 0.9073 - val_loss: 0.3158\n",
      "Epoch 12/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 1s/step - accuracy: 0.9378 - loss: 0.1977 - val_accuracy: 0.8975 - val_loss: 0.3615\n",
      "Epoch 13/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 1s/step - accuracy: 0.9366 - loss: 0.2054 - val_accuracy: 0.9045 - val_loss: 0.3316\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 1s/step - accuracy: 0.9386 - loss: 0.1991 - val_accuracy: 0.8932 - val_loss: 0.3782\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    d_model=config[\"d_model\"],\n",
    "    num_heads=config[\"num_heads\"],\n",
    "    dff=4 * config[\"d_model\"],\n",
    "    block_size=62,\n",
    "    dropout_rate=config[\"dropout_rate\"],\n",
    "    num_classes=30,\n",
    ")\n",
    "lr = CustomSchedule(config[\"d_model\"])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=100,\n",
    "    callbacks=get_callbacks(\"../models/\" + path),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 650ms/step - accuracy: 0.9154 - loss: 0.3063\n"
     ]
    }
   ],
   "source": [
    "eval_and_save(model_type, model, ds_test, config, history, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
