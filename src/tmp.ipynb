{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 03:56:56.349837: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-27 03:56:58.487609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_folder_structure(source_folder, destination_folder):\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    for item in os.listdir(source_folder):\n",
    "        source_item = os.path.join(source_folder, item)\n",
    "        destination_item = os.path.join(destination_folder, item)\n",
    "\n",
    "        if os.path.isdir(source_item):\n",
    "            copy_folder_structure(source_item, destination_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files_based_on_list(source_folder, destination_folder, file_list):\n",
    "    for filename in file_list:\n",
    "        filename = filename[:-1]\n",
    "        source_file = os.path.join(source_folder, filename)\n",
    "        destination_file = os.path.join(destination_folder, filename)\n",
    "\n",
    "        if os.path.exists(source_file):\n",
    "            shutil.move(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(source_folder):\n",
    "    destination_folder = \"../data/test\"\n",
    "    copy_folder_structure(source_folder, destination_folder)\n",
    "    with open(\"../data/train/testing_list.txt\", 'r') as f:\n",
    "        testing_files = f.readlines()\n",
    "    move_files_based_on_list(source_folder, destination_folder, testing_files)\n",
    "\n",
    "    destination_folder = \"../data/val\"\n",
    "    copy_folder_structure(source_folder, destination_folder)\n",
    "    with open(\"../data/train/validation_list.txt\", 'r') as f:\n",
    "        validation_files = f.readlines()\n",
    "    move_files_based_on_list(source_folder, destination_folder, validation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates test and val folder so it is easy to load the data with tf.keras.utils.audio_dataset_from_directory\n",
    "make_dataset(\"../data/train/audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51088 files belonging to 30 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 03:57:11.670870: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-27 03:57:12.128505: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-27 03:57:12.128583: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-27 03:57:12.134980: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-27 03:57:12.135067: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-27 03:57:12.135113: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-27 03:57:14.845167: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-27 03:57:14.845259: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-27 03:57:14.845271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-27 03:57:14.845330: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-27 03:57:14.845508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3840 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "ds_train = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory='../data/train/audio',\n",
    "    batch_size=256,\n",
    "    seed=1337,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6798 files belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_val = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory='../data/val/',\n",
    "    batch_size=256,\n",
    "    seed=1337,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6835 files belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_test = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory='../data/test/',\n",
    "    batch_size=256,\n",
    "    seed=1337,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 16000, 1)\n",
      "(256,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 03:57:19.910587: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x, y in ds_train.take(1):\n",
    "    print(x.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrograms(waveforms, labels):\n",
    "  waveforms = tf.reshape(waveforms, [-1, 16000])\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveforms, frame_length=255, frame_step=128)\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([256, 124, 129, 1]), TensorShape([256]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec, label = get_spectrograms(x, y)\n",
    "spec.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(get_spectrograms)\n",
    "ds_val = ds_val.map(get_spectrograms)\n",
    "ds_test = ds_test.map(get_spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([256, 124, 129, 1]), TensorShape([256]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y in ds_train.take(1):\n",
    "    break\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will probably end up in utils.py or sth like that\n",
    "from typing import Dict, List, Union\n",
    "import pandas as pd\n",
    "def get_callbacks(path: str) -> List[tf.keras.callbacks.Callback]:\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_accuracy\", patience=4\n",
    "    )\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        path, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\"\n",
    "    )\n",
    "    return [early_stopping, checkpoint]\n",
    "\n",
    "def eval_and_save(\n",
    "    model_type: str,\n",
    "    ds_test: tf.data.Dataset,\n",
    "    config: Dict[str, Union[int, str, float]],\n",
    "    history: Dict[str, List[float]],\n",
    "    path: str,\n",
    ") -> None:\n",
    "    model = tf.keras.models.load_model(\"../models/\" + path)\n",
    "    loss, acc = model.evaluate(ds_test)\n",
    "\n",
    "    history = pd.DataFrame(history.history)\n",
    "    history.to_csv(f\"../history/{path.split('.')[0]}.csv\")\n",
    "\n",
    "    with open(\"../results/results.csv\", \"a\") as f:\n",
    "        f.write(f\"{model_type};{model.count_params()};{loss};{acc};{config};{path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"CNN2D_1.keras\"\n",
    "model_type = \"CNN2D\"\n",
    "# not sure what to put here, but for now this will do\n",
    "config = {\n",
    "    \"Data Augmentation\": \"No\",\n",
    "    \"Regularization\": \"No\",\n",
    "    \"Optimizer\": \"Adam\",\n",
    "    \"Learning Rate\": 0.001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(124, 129, 1)),\n",
    "    tf.keras.layers.Resizing(32, 32),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(30),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=config[\"Learning Rate\"]),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714183043.571636  174648 service.cc:145] XLA service 0x7f4ec40048f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714183043.572213  174648 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2060 with Max-Q Design, Compute Capability 7.5\n",
      "2024-04-27 03:57:24.281009: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-27 03:57:32.819555: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/200\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11:58\u001b[0m 22s/step - accuracy: 0.0352 - loss: 3.4127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1714183063.276806  174648 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 122ms/step - accuracy: 0.3030 - loss: 2.5734 - val_accuracy: 0.6420 - val_loss: 1.3151\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 90ms/step - accuracy: 0.6981 - loss: 1.1032 - val_accuracy: 0.7555 - val_loss: 0.9354\n",
      "Epoch 3/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.8006 - loss: 0.7138 - val_accuracy: 0.7886 - val_loss: 0.7967\n",
      "Epoch 4/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.8520 - loss: 0.5219 - val_accuracy: 0.8064 - val_loss: 0.7572\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.8823 - loss: 0.4126 - val_accuracy: 0.8111 - val_loss: 0.7474\n",
      "Epoch 6/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9031 - loss: 0.3348 - val_accuracy: 0.8210 - val_loss: 0.7746\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9175 - loss: 0.2847 - val_accuracy: 0.8277 - val_loss: 0.7756\n",
      "Epoch 8/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.9341 - loss: 0.2283 - val_accuracy: 0.8282 - val_loss: 0.8353\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9415 - loss: 0.2055 - val_accuracy: 0.8311 - val_loss: 0.8710\n",
      "Epoch 10/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9477 - loss: 0.1818 - val_accuracy: 0.8292 - val_loss: 0.9272\n",
      "Epoch 11/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9502 - loss: 0.1733 - val_accuracy: 0.8372 - val_loss: 0.9235\n",
      "Epoch 12/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.9550 - loss: 0.1558 - val_accuracy: 0.8327 - val_loss: 0.9249\n",
      "Epoch 13/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.9594 - loss: 0.1417 - val_accuracy: 0.8395 - val_loss: 0.9431\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.9648 - loss: 0.1256 - val_accuracy: 0.8366 - val_loss: 0.9956\n",
      "Epoch 15/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.9700 - loss: 0.1026 - val_accuracy: 0.8385 - val_loss: 1.0319\n",
      "Epoch 16/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9723 - loss: 0.1005 - val_accuracy: 0.8411 - val_loss: 1.0243\n",
      "Epoch 17/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9689 - loss: 0.1074 - val_accuracy: 0.8392 - val_loss: 1.0945\n",
      "Epoch 18/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9634 - loss: 0.1241 - val_accuracy: 0.8402 - val_loss: 1.0572\n",
      "Epoch 19/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9751 - loss: 0.0913 - val_accuracy: 0.8405 - val_loss: 1.0873\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9798 - loss: 0.0750 - val_accuracy: 0.8404 - val_loss: 1.1478\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train, epochs=100, validation_data=ds_val, callbacks=get_callbacks(\"../models/\" + path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8273 - loss: 1.2903\n"
     ]
    }
   ],
   "source": [
    "eval_and_save(model_type, ds_test, config, history, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
